<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Ryan Gebrael" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Predicting Medical School Admissions</title>
    <meta name="generator" content="Hugo 0.79.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Predicting Medical School Admissions</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         November 18, 2020 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<p>After spending too much time researching admission statistics for various medical schools, I decided to use my time more wisely by exploring a medical school acceptance dataset for my next project. The dataset is titled &quot;MedGPA&quot;, and includes information on 55 medical school applicants from a Midwest liberal arts college. The dataset includes 12 variables. Acceptance status is displayed both through letters (A for accepted and D for denied) and through binary (1 for accepted and 0 for denied). MCAT score is included based on the old MCAT scoring system, and each MCAT subscore is also included (Verbal Reasoning, Phyiscal Sciences, Writing Sample, and Biological Sciences). GPA and Science GPA (BCPM Bio/Chem/Physics/Math GPA) were also included, as well as sex, number of medical schools applied to (Apps), and applicant number. Since the dataset was missing the MCAT Writing Sample susbscore for applicant #54, this applicant was removed from the dataset. Now the dataset contains 54 observations.</p>
<pre class="r"><code>library(tidyverse)
MedGPA &lt;- read_csv(&quot;MedGPA.csv&quot;)
MedGPA &lt;- MedGPA %&gt;% rename(Applicant = X1)
MedGPA &lt;- MedGPA[-54, ]
MedGPA</code></pre>
<pre><code>## # A tibble: 54 x 12
##    Applicant Accept Acceptance Sex    BCPM   GPA    VR    PS    WS    BS  MCAT
##        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1         1 D               0 F      3.59  3.62    11     9     9     9    38
##  2         2 A               1 M      3.75  3.84    12    13     8    12    45
##  3         3 A               1 F      3.24  3.23     9    10     5     9    33
##  4         4 A               1 F      3.74  3.69    12    11     7    10    40
##  5         5 A               1 F      3.53  3.38     9    11     4    11    35
##  6         6 A               1 M      3.59  3.72    10     9     7    10    36
##  7         7 A               1 M      3.85  3.89    11    12     6    11    40
##  8         8 D               0 M      3.26  3.34    11    11     8     9    39
##  9         9 A               1 F      3.74  3.71     8    10     6    11    35
## 10        10 A               1 F      3.86  3.89     9     9     6    10    34
## # â€¦ with 44 more rows, and 1 more variable: Apps &lt;dbl&gt;</code></pre>
<pre class="r"><code>library(rstatix)
group &lt;- MedGPA$Accept
DVs &lt;- MedGPA %&gt;% select(GPA, BCPM, MCAT, Apps)
sapply(split(DVs, group), mshapiro_test)</code></pre>
<pre><code>##           A         D          
## statistic 0.9533242 0.8701898  
## p.value   0.2073555 0.005305916</code></pre>
<p>In order to perform a MANOVA, the data was tested to see if MANOVA assumptions were met. The multivariate normality for each group was tested using the Shapiro-Wilk test. For the subset of people who were accepted, the p-value from the test was 0.2073555. For the group of people who were denied admission, the p-value was 0.005305916, which means the null hypothesis is rejected and the multivariate normality assumption was violated. After testing the assumptions, the MANOVA was carried out testing if GPA, science GPA, MCAT score, and number of applications sent out experienced a mean difference based on whether an applicant was accepted or not.</p>
<pre class="r"><code>manMedGPA &lt;- manova(cbind(GPA, BCPM, MCAT, Apps) ~ Accept, data = MedGPA)
summary(manMedGPA)</code></pre>
<pre><code>##           Df  Pillai approx F num Df den Df    Pr(&gt;F)    
## Accept     1 0.31646   5.6713      4     49 0.0007833 ***
## Residuals 52                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The MANOVA resulted in a P-value of 0.0007833, suggesting that at least one of the numeric variables shows a mean difference based on admission status. To determine which numeric variables showed a mean difference based on admission status, four univariate ANOVAs were performed.</p>
<pre class="r"><code>summary.aov(manMedGPA)</code></pre>
<pre><code>##  Response GPA :
##             Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Accept       1 1.0735 1.07352  20.083 4.101e-05 ***
## Residuals   52 2.7796 0.05345                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response BCPM :
##             Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Accept       1 1.3925 1.39249  16.403 0.0001712 ***
## Residuals   52 4.4144 0.08489                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response MCAT :
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## Accept       1 143.01 143.008  9.6599 0.003051 **
## Residuals   52 769.83  14.804                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response Apps :
##             Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Accept       1    5.07  5.0704  0.2186  0.642
## Residuals   52 1205.97 23.1917</code></pre>
<p>The p-value for the ANOVA that tested the mean difference for number of applications submitted based on admission status was 0.642, and is evidence that the mean difference in number of applications submitted based on admission status is insignificant. For GPA (4.101e-05), BCPM (0.0001712), and MCAT (0.003051), the mean difference p-values were all significant. This is evidence that the mean difference for each of these factors is significant based on admission status. Since there were only two acceptance statuses there was no need to perform any post-hoc t-tests.</p>
<pre class="r"><code>1 - 0.95^5</code></pre>
<pre><code>## [1] 0.2262191</code></pre>
<pre class="r"><code>0.05/5</code></pre>
<pre><code>## [1] 0.01</code></pre>
<p>One MANOVA and four univariate ANOVAS tests were performed, for a total of 5 tests. This means that the probability of at least one type-I error occuring is 1-0.95^5 = 0.2262191. The Bonferroni correction was applied to get a new significance value 0.05/5=0.01. This adjustment did not result in any different conclusions based on significance compared to the original conclusions that were made.</p>
<pre class="r"><code>rand_dist &lt;- vector()
for (i in 1:5000) {
    new &lt;- data.frame(GPA = sample(MedGPA$GPA), Accept = MedGPA$Accept)
    rand_dist[i] &lt;- mean(new[new$Accept == &quot;D&quot;, ]$GPA) - mean(new[new$Accept == 
        &quot;A&quot;, ]$GPA)
}

MedGPA %&gt;% group_by(Accept) %&gt;% summarize(means = mean(GPA)) %&gt;% 
    summarize(mean_diff = diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1    -0.284</code></pre>
<pre class="r"><code>mean(rand_dist &gt; 0.28375 | rand_dist &lt; -0.28375)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>{
    hist(rand_dist, main = &quot;&quot;, ylab = &quot;&quot;, xlim = c(-0.3, 0.3))
    abline(v = c(-0.28375, 0.28375), col = &quot;red&quot;)
}</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /> A randomization test was performed to determine the mean difference in GPA based on admissions status, and to determine if this difference was significant. The null hypothesis was that the mean difference in GPA based on admission status was 0, and the alternative hypothesis was that the mean difference was not 0. The relationships between the variables were scrambled by randomizing the columns and generating a null distribution to compare against an observed test statistic. The mean difference subtracting admitted applicant GPAs from denied applicant GPAs was calculated to be -0.28375, and the calculated p-value was extremely small (2e-04), which means that the null hypothesis was rejected and the mean difference in GPA based on admission status was significant. A histogram was generated showing how far out the actual difference in mean GPA was from the distribution.</p>
<pre class="r"><code>library(sandwich)
library(lmtest)
MedGPA$GPA_c &lt;- MedGPA$GPA - mean(MedGPA$GPA)
fit &lt;- lm(MCAT ~ Sex * GPA_c, data = MedGPA)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MCAT ~ Sex * GPA_c, data = MedGPA)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.7483 -3.0669 -0.0158  2.1076  9.1542 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  36.1967     0.7155  50.589   &lt;2e-16 ***
## SexM          0.8273     1.0310   0.802   0.4261    
## GPA_c         8.6614     2.9978   2.889   0.0057 ** 
## SexM:GPA_c   -3.0174     3.9157  -0.771   0.4446    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.783 on 50 degrees of freedom
## Multiple R-squared:  0.2163, Adjusted R-squared:  0.1693 
## F-statistic: 4.599 on 3 and 50 DF,  p-value: 0.006413</code></pre>
<pre class="r"><code>ggplot(MedGPA, aes(GPA, MCAT, color = Sex)) + geom_smooth(method = &quot;lm&quot;, 
    se = F, fullrange = T) + geom_point()</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /> A linear regression model was create predicting the MCAT score based on sex and mean centered GPA (with interaction). Based on the regression, a female applicant with an average GPA is predicted to have an MCAT score of 36.1967. A male applicant with an average GPA is expected to score 0.8273 higher on the MCAT than a female applicant with an average GPA. Finally, the slope for GPA on MCAT score is 3.0174 less for males compared to females. The adjusted R-squared value for the fit was found to be 0.1693, meaning that 0.1693 of the variation in MCAT score is explained by the model.</p>
<pre class="r"><code>resids &lt;- fit$residuals
fitvals &lt;- fit$fitted.values
ggplot() + geom_point(aes(fitvals, resids)) + geom_hline(yintercept = 0, 
    color = &quot;red&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot() + geom_histogram(aes(resids), bins = 20)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-8-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>qqnorm(resids)
qqline(resids, col = &quot;red&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-8-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ks.test(resids, &quot;pnorm&quot;, mean = 0, sd(resids))</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  resids
## D = 0.073236, p-value = 0.9137
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>bptest(fit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 2.5663, df = 3, p-value = 0.4634</code></pre>
<p>To check that the assumptions for a linear regression were met, a plot comparing the residuals to the fitted values was generated. This plot appeared to include data points that were generally randomly distributed, suggesting linearity. A plot with the distribution of the residuals was generated and the distribution appeared to be somewhat normal. A Q-Q plot was generated and appeared normal, and a Kolmogorov-Smirnov test was performed and resulted in a p-value of 0.9137. This p-value means we fail to reject the null hypothesis of normality in the residuals. The regression plot did not show a fanning pattern, and a Breusch-Pagan test to assess homoskedasticity resulted in a p-value of 0.4634, meaning the data was homoskedastic and the variances were equal throughout the model. All of the main assumptions for a linear regression appeared to be met.</p>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 36.19669    0.70726 51.1785   &lt;2e-16 ***
## SexM         0.82731    1.07337  0.7708   0.4445    
## GPA_c        8.66138    3.43073  2.5246   0.0148 *  
## SexM:GPA_c  -3.01739    4.18204 -0.7215   0.4740    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Recomputing the regression using robust standard errors resulted in the calculation of larger standard errors for each coefficient, and larger p-values. Overall, this did not cause any significant change.</p>
<pre class="r"><code>samp_distn &lt;- replicate(5000, {
    boot_dat &lt;- MedGPA %&gt;% sample_frac(replace = TRUE)
    fit &lt;- lm(MCAT ~ Sex * GPA_c, data = boot_dat)
    coef(fit)
})

samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)     SexM    GPA_c SexM:GPA_c
## 1    0.656757 1.018496 3.270398   4.174336</code></pre>
<p>The regression was then rerun using bootstrapped standard errors by resampling the observations. The standard error for SexM decreased very slightly compared to the original sample, meaning the p-value likely decreased. The standard error for GPA_c and the standard error for the interaction between SexM and GPA_c increased, meaning the p-value for each of these increased.</p>
<pre class="r"><code>MedGPA$MCAT_c &lt;- MedGPA$MCAT - mean(MedGPA$MCAT)
fit &lt;- glm(Acceptance ~ GPA_c + MCAT_c, data = MedGPA, family = &quot;binomial&quot;)

coeftest(fit)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  0.33179    0.34063  0.9740 0.330036   
## GPA_c        4.67359    1.64236  2.8457 0.004432 **
## MCAT_c       0.16419    0.10337  1.5883 0.112211   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit))</code></pre>
<pre><code>## (Intercept)       GPA_c      MCAT_c 
##    1.393455  107.081457    1.178434</code></pre>
<p>A logistic regression was created predicting acceptance (a binary variable) based on mean centered GPA and mean centered MCAT score. The odds of acceptance for someone with an average GPA and MCAT score are 1.393455. Controlling for MCAT score, a GPA increase of 1 increases the odds of acceptance by a factor of 107.08, which is a significant difference. Controlling for GPA, an MCAT score increase of 1 increases the odds of acceptance by a factor of 1.18, which is not a significant difference.</p>
<pre class="r"><code>MedGPA$prob &lt;- predict(fit, type = &quot;response&quot;)
MedGPA$predicted &lt;- ifelse(MedGPA$prob &gt; 0.5, &quot;A&quot;, &quot;D&quot;)
table(truth = MedGPA$Accept, prediction = MedGPA$predicted) %&gt;% 
    addmargins</code></pre>
<pre><code>##      prediction
## truth  A  D Sum
##   A   23  7  30
##   D    7 17  24
##   Sum 30 24  54</code></pre>
<pre class="r"><code>prob &lt;- predict(fit, type = &quot;response&quot;)
class_diag(prob, MedGPA$Acceptance)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1       auc
## 1 0.7407407 0.7666667 0.7083333 0.7666667 0.7666667 0.8277778</code></pre>
<pre class="r"><code>library(plotROC)
ROCplot &lt;- ggplot(MedGPA) + geom_roc(aes(d = Acceptance, m = GPA_c + 
    MCAT_c, A = 1), n.cuts = 0)
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-12-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7472222</code></pre>
<p>A confusion matrix was generated for the logistic regression by comparing the true acceptances to the acceptances that were predicted by the model. The accuracy (proportion of correctly predicted cases) of the model was calculated to be 0.7407407, the sensitivity (proportion of correctly predicted acceptances) was calculated to be 0.7666667, the specificity (proportion of correctly predicted rejections) was 0.7083333, the precision (proportion of predicted acceptances who were actualy accepted) was 0.7666667, and the auc was 0.8277778. Next a ROC curve was generated and the auc (area under the curve) was calculated to be 0.7472222, suggesting that the model is a fair fit for the data.</p>
<pre class="r"><code>MedGPA$logit &lt;- predict(fit)
MedGPA %&gt;% mutate(Accept = factor(Accept, levels = c(&quot;D&quot;, &quot;A&quot;))) %&gt;% 
    ggplot(aes(logit, fill = Accept)) + geom_density(alpha = 0.5) + 
    geom_vline(xintercept = 0, lty = 2)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" /> The logit scores were plotted for the two acceptance statuses to visualize the data that was classified correctly compared to what was misclassified.</p>
<pre class="r"><code>fit &lt;- glm(Acceptance ~ GPA + Sex + BCPM + Apps + BS + PS + WS + 
    VR, data = MedGPA, family = &quot;binomial&quot;)
coeftest(fit)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -46.641392  15.599671 -2.9899 0.002791 **
## GPA          12.397279   8.610710  1.4398 0.149938   
## SexM         -2.283542   1.429461 -1.5975 0.110158   
## BCPM         -6.163325   6.963006 -0.8852 0.376074   
## Apps          0.051198   0.147234  0.3477 0.728038   
## BS            1.918392   0.681825  2.8136 0.004899 **
## PS            1.167257   0.539463  2.1637 0.030484 * 
## WS           -0.778431   0.395588 -1.9678 0.049093 * 
## VR            0.079037   0.310589  0.2545 0.799129   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>MedGPA$prob &lt;- predict(fit, type = &quot;response&quot;)

MedGPA$predicted &lt;- ifelse(MedGPA$prob &gt; 0.5, &quot;A&quot;, &quot;D&quot;)
table(truth = MedGPA$Accept, prediction = MedGPA$predicted) %&gt;% 
    addmargins</code></pre>
<pre><code>##      prediction
## truth  A  D Sum
##   A   27  3  30
##   D    3 21  24
##   Sum 30 24  54</code></pre>
<pre class="r"><code>prob &lt;- predict(fit, type = &quot;response&quot;)
class_diag(prob, MedGPA$Acceptance)</code></pre>
<pre><code>##         acc sens  spec ppv  f1  auc
## 1 0.8888889  0.9 0.875 0.9 0.9 0.95</code></pre>
<p>Next, a logistic regression was created predicting acceptance based on GPA, Science GPA, each of the MCAT subscores, Sex, and the number of applications submitted. A significant p-value was generated for three of the MCAT subscores, BS, PS, and WS. The accuracy of the model was calculated to be 0.8888889, the sensitivity was calculated to be 0.9, the specificity was 0.875, the precision was 0.9, and the auc was 0.95, suggesting the model was a great fit.</p>
<pre class="r"><code>set.seed(1234)
k = 10
data &lt;- MedGPA[sample(nrow(MedGPA)), ]
folds &lt;- cut(seq(1:nrow(MedGPA)), breaks = k, labels = F)

diags &lt;- NULL
for (i in 1:k) {
    
    train &lt;- data[folds != i, ]
    test &lt;- data[folds == i, ]
    
    truth &lt;- test$Acceptance
    
    
    fit &lt;- glm(Acceptance ~ GPA + Sex + BCPM + Apps + BS + PS + 
        WS + VR, data = MedGPA, family = &quot;binomial&quot;)
    
    
    probs &lt;- predict(fit, newdata = test, type = &quot;response&quot;)
    
    
    diags &lt;- rbind(diags, class_diag(probs, truth))
}

summarize_all(diags, mean)</code></pre>
<pre><code>##         acc      sens      spec  ppv        f1       auc
## 1 0.8933333 0.8916667 0.8966667 0.88 0.8712698 0.9722222</code></pre>
<p>A 10-fold cross validation to test how well the model performs on new data. The data was split into two parts and the model was fit to one part and tested on the other part, doing this multiple times to measure the average performance of the model. The accuracy of the model was calculated to be 0.8933333, the sensitivity was calculated to be 0.8916667, the specificity was 0.8966667, the precision was 0.88, and the auc was 0.9722222, suggesting the model was a great fit. The auc from the cross validation was slightly higher than the auc from the initial regression. The model appears to do well at making predictions on new data.</p>
<pre class="r"><code>library(glmnet)
y &lt;- as.matrix(MedGPA$Acceptance)  #grab response
x &lt;- model.matrix(Acceptance ~ ., data = MedGPA)[, -c(1, 2, 3, 
    13, 14, 15, 16, 17)]
cv &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;)
lasso &lt;- glmnet(x, y, family = &quot;binomial&quot;, lambda = cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 10 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     s0
## (Intercept) -3.9374111
## SexM         .        
## BCPM         .        
## GPA          0.6376048
## VR           .        
## PS           .        
## WS           .        
## BS           0.1923299
## MCAT         .        
## Apps         .</code></pre>
<p>LASSO was performed on the model and the variables that were always retained were GPA and BS (the Behavioral Science subscore of the MCAT).</p>
<pre class="r"><code>set.seed(1234)
k = 10
data &lt;- MedGPA[sample(nrow(MedGPA)), ]
folds &lt;- cut(seq(1:nrow(MedGPA)), breaks = k, labels = F)

diags &lt;- NULL
for (i in 1:k) {
    
    train &lt;- data[folds != i, ]
    test &lt;- data[folds == i, ]
    
    truth &lt;- test$Acceptance
    
    
    fit &lt;- glm(Acceptance ~ GPA + BS, data = MedGPA, family = &quot;binomial&quot;)
    
    
    probs &lt;- predict(fit, newdata = test, type = &quot;response&quot;)
    
    
    diags &lt;- rbind(diags, class_diag(probs, truth))
}

summarize_all(diags, mean)</code></pre>
<pre><code>##    acc      sens      spec  ppv        f1       auc
## 1 0.82 0.8333333 0.7966667 0.83 0.8019841 0.8736111</code></pre>
<p>The 10-fold cross validation was repeated, this time using only the variables that were selected by LASSO (GPA and BS). The out-of-sample AUC was calculated to be 0.8736111, which is lower than the previous AUC calculations for the logistic models but regardless it suggests that this model is a good fit.</p>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with â™¥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
